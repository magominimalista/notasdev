Vamos criar a rotina para entrega no servidor da AWS

O projeto base:
https://github.com/alura-cursos/Curso_CI_3

Vamos em .gihub/workflows no arquivo `go.yml` depois da última linha acrescente

```yaml
// cód. omitido...

  Deploy_EC2:
    needs: build
    uses: ./.github/workflows/EC2.yml
    secrets: inherit
```

E pelo código temos que criar um arquivo `EC2.yml`

```yaml
name: Entrega contínua

on:
  workflow_call:

jobs:

  EC2:
     runs-on: ubuntu-latest
     steps:
      - name: Download a Build Artifact
      
      uses: actions/download-artifact@v3.0.0
      with:
    # Artifact name
        name: programa
            - uses: actions/checkout@v3
```

Nosso código tá quase pronto, agora agente precisa fazer o deploy na nossa Máquina Virtual. Vamos dá uma olhada nesse plugin do SSH deploy

![[Pasted image 20221215155232.png]]

Vamos adicionar essa parte em `EC2.yml` 

```yaml
  - name: Deploy to Staging server
    uses: easingthemes/ssh-deploy@main
    with:
      SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
      REMOTE_HOST: ${{ secrets.REMOTE_HOST }}
      REMOTE_USER: ${{ secrets.REMOTE_USER }}
      TARGET: /home/${{ secrets.REMOTE_TARGET }}
      EXCLUDE: "postgres-data"
```

Não queremos que a pasta com o postgre de teste vá para o servidor, por isso usamo o exclude. 

![[Pasted image 20221215171002.png]]

Agora basta criar os segredos com a chave que foi gerada na criação do container, o host remoto (endereço de ip), usuário e target.

Para achar o nome de usuário basta clicar na instancia do host. Este usuário é criado automaticamente pela AWS.

![[Pasted image 20221215171555.png]]

Essa parte tá ficando grande mais ainda faz parte da rotina.

Vamos precisar adicionar alguns comandos SSH para concluir nosso script. Vamos no marketplace buscar por SSH Remote Commands. Além disso precisamos criar algumas variáveis de ambiente para fazer com que o nosso banco de dados funcione. Faremos isso usando um script e usaremos | para que o código de script suporte várias linhas.

> O go usa uma variável de ambiente padrão chamada PORT. Por tanto não podemos fazer uso deste nome em específico. Neste caso, como foi algo percebido agora, onde tiver PORT no nosso código precisamos alterar para DBPORT. Isso inclui nosso Dockerfile


```yaml
    - name: executing remote ssh commands using password
      uses: appleboy/ssh-action@master
      with:
        host: ${{ secrets.REMOTE_HOST }}
        username: ${{ secrets.REMOTE_USER }}
        key: ${{ secrets.SSH_PRIVATE_KEY}}
        port: 22
        script: |
	        export HOST=${{ secrets.DBHOST }}
	        export USER=${{ secrets.DBUSER }}
	        export PASSWORD=${{ secrets.DBPASSWORD }}
	        export DBNAME=${{ secrets.DBNAME }}
	        export DBPORT=${{ secrets.DBPORT }}
	        export PORT=8000
```

Agora precisamos colocar esses segredos no nosso secrets. Vamos pegar essas informações em nossas instâncias da AWS. O DBHOST será nosso Endpoint

![[Pasted image 20221216075707.png]]

![[Pasted image 20221216075822.png]]

O nosso usuário e senha criamos no momento que criamos o banco, assim como o nome do banco.

#Github #AWS 